{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# W207 Baseline Submission\n## Group 2: Austin Jin, Matt Lyons, Chandni Shah","metadata":{}},{"cell_type":"markdown","source":"<b> Project Link:</b> https://www.kaggle.com/c/petfinder-pawpularity-score\n\n<b> Project Description:</b><br>\n\"In this competition, you’ll analyze raw images and metadata to predict the “Pawpularity” of pet photos. Your task is to predict engagement with a pet's profile based on the photograph for that profile. You are also provided with hand-labelled metadata for each photo. The dataset for this competition therefore comprises both images and tabular data.\" <br><br>\n\n\"Tabular Metadata: Each pet photo is labeled with the value of 1 (Yes) or 0 (No) for each of the following features. These labels are not used for deriving the Pawpularity score.\n\n- Focus - Pet stands out against uncluttered background, not too close / far.\n- Eyes - Both eyes are facing front or near-front, with at least 1 eye / pupil decently clear.\n- Face - Decently clear face, facing front or near-front.\n- Near - Single pet taking up significant portion of photo (roughly over 50% of photo width or height).\n- Action - Pet in the middle of an action (e.g., jumping).\n- Accessory - Accompanying physical or digital accessory / prop (i.e. toy, digital sticker), excluding collar and leash.\n- Group - More than 1 pet in the photo.\n- Collage - Digitally-retouched photo (i.e. with digital photo frame, combination of multiple photos).\n- Human - Human in the photo.\n- Occlusion - Specific undesirable objects blocking part of the pet (i.e. human, cage or fence). Note that not all blocking objects are considered occlusion.\n- Info - Custom-added text or labels (i.e. pet name, description).\n- Blur - Noticeably out of focus or noisy, especially for the pet’s eyes and face. For Blur entries, “Eyes” column is always set to 0.\"","metadata":{}},{"cell_type":"markdown","source":"## Part I - Metadata EDA","metadata":{}},{"cell_type":"markdown","source":"### In order to better understand the 'petfinder-pawpularity-score' dataset, we have performed some early EDA by performing the following pre-requisites:","metadata":{}},{"cell_type":"markdown","source":"## 1. Load in the packages","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom tensorflow import keras\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.client import device_lib\nimport tensorflow as tf\nfrom matplotlib import image\nfrom glob import glob\nimport cv2\n\n%matplotlib inline\n\nimport time\nfrom matplotlib.ticker import MultipleLocator\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom math import sqrt\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:41:54.757197Z","iopub.execute_input":"2021-11-17T01:41:54.757739Z","iopub.status.idle":"2021-11-17T01:41:54.772070Z","shell.execute_reply.started":"2021-11-17T01:41:54.757701Z","shell.execute_reply":"2021-11-17T01:41:54.771182Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"%%capture\n\n# Perform a for loop to browse through the 'petfinder-pawpularity-score' directory and print out all file names:\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:42:13.151833Z","iopub.execute_input":"2021-11-17T01:42:13.152107Z","iopub.status.idle":"2021-11-17T01:42:14.475136Z","shell.execute_reply.started":"2021-11-17T01:42:13.152077Z","shell.execute_reply":"2021-11-17T01:42:14.474361Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Define the source path for the Pawpularity contest data, retrieve and assign the .csv metadata into DataFrames, and retrieve and assign the .jpq image data into lists:\n# path = '../input/petfinder-pawpularity-score/'\n\ntrain_df = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntest_df = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\n\ntrain_jpg = glob(\"../input/petfinder-pawpularity-score/train/*.jpg\")\ntest_jpg = glob(\"../input/petfinder-pawpularity-score/test/*.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:42:15.327977Z","iopub.execute_input":"2021-11-17T01:42:15.328552Z","iopub.status.idle":"2021-11-17T01:42:15.390701Z","shell.execute_reply.started":"2021-11-17T01:42:15.328512Z","shell.execute_reply":"2021-11-17T01:42:15.389902Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Printing the dimensions for the train metadata.\nprint('train_df dimensions: ', train_df.shape)\nprint('train_df column names: ', train_df.columns.values.tolist())\n\n# Adding a space in between the dimensions for the train and test metadata\nprint('')\n\n# Printing the dimensions for the test metadata\nprint('test_df dimensions: ',test_df.shape)\nprint('test_df column names: ', test_df.columns.values.tolist())\n\n# After printing the shape of the train_df and test_df DataFrames, we have noticed that the train_df has 9912 rows and 14 columns whereas the test_df only has 8 rows and 13 columns. It is also worth mentioning that the test_df dataframe doesn't contain the pawpularity score.","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:42:17.782902Z","iopub.execute_input":"2021-11-17T01:42:17.783766Z","iopub.status.idle":"2021-11-17T01:42:17.790975Z","shell.execute_reply.started":"2021-11-17T01:42:17.783720Z","shell.execute_reply":"2021-11-17T01:42:17.790298Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### After printing the shape of the train_df and test_df dataframes, we can see that the train_df has 14 columns and 9912 rows, while the test_df only has 13 columns and 8 rows. It is also worth noting that the test_df particulary hasn't have pawpularity score data attached to it. We have further explored the metadata in the train dataframe since it would be the dataset for building out our models and have decided to utilize the test dataframe for practicing some predictions since it didn't contain a column for pawpularity score:","metadata":{}},{"cell_type":"code","source":"# Display the first 10 rows of the train_df dataframe\ntrain_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:33:16.745961Z","iopub.execute_input":"2021-11-17T01:33:16.746636Z","iopub.status.idle":"2021-11-17T01:33:16.772042Z","shell.execute_reply.started":"2021-11-17T01:33:16.746597Z","shell.execute_reply":"2021-11-17T01:33:16.771333Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### It was noticed that train_df still contains ID's of the photos which means that we won't be necessarily using this metadata when building out the models. Since we figured that it would be useful to also take a look athe distribution of the target variable, which would be the Pawpularity Score in the ranges from 1-100, a simple histogram has been plotted out to view the distribution:","metadata":{}},{"cell_type":"code","source":"# Distribution for Pawpularity Scores\n\nsns.set(rc={'figure.figsize':(15,5)})\nfig = plt.figure()\nsns.histplot(data=train_df, x='Pawpularity', bins=100)\nplt.axvline(train_df['Pawpularity'].mean(), c='red', ls='-', lw=3, label='Mean Pawpularity')\nplt.axvline(train_df['Pawpularity'].median(),c='blue',ls='-',lw=3, label='Median Pawpularity')\nplt.title('Distribution of Pawpularity Scores', fontsize=20, fontweight='bold')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:33:19.523465Z","iopub.execute_input":"2021-11-17T01:33:19.524177Z","iopub.status.idle":"2021-11-17T01:33:20.053933Z","shell.execute_reply.started":"2021-11-17T01:33:19.524139Z","shell.execute_reply":"2021-11-17T01:33:20.053193Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### After taking a look at the histogram, we see that there is a skew in the distribution of the pawpularity scores. It was interesting to see that there is a small curve close to zero Pawpularity along with another curve at the 100 Pawpularity Score with a count of close to 300. Since the EDA alone doesn't allow us to truly know the reason as to why there were many scores at 100, we have decided to keep the following theories in mind:\n\n##### - Was there something unique about the animals such as their age, color, or breed that was most desirable by the people visiting the site?\n##### - Did it have to do with the way in which photos were taken that were leading to more clicks and thus a higher Pawpularity score?\n##### - Did it have to do with the Pawpularity score itself?\n##### - Were there any outliers that need to be removed from the training data to improve the models that were built?\n##### - Was there perhaps any noise in the dataset that caused the huge increase in pawpularity scores of 100?\n\n### Since we are unable to find the actual answer through EDA alone, we plan on looking to develop concrete ML models that will allow us to see which features make more impact on the high pawpularity score in order to further explain the curves.","metadata":{}},{"cell_type":"code","source":"# Describe the distribution of the train dataframe in a numerical way\n\ntrain_df[['Pawpularity']].describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:33:23.138110Z","iopub.execute_input":"2021-11-17T01:33:23.138636Z","iopub.status.idle":"2021-11-17T01:33:23.158782Z","shell.execute_reply.started":"2021-11-17T01:33:23.138599Z","shell.execute_reply":"2021-11-17T01:33:23.158045Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Put column names into a list\nfeature_variables = train_df.columns.values.tolist()\n\n# For each feature variable, doesn't include Id and Pawpularity by using [1:-1]\n# Display a boxplot and distribution plot against pawpularity\nfor variable in feature_variables[1:-1]:\n    fig, ax = plt.subplots(1,2)\n    sns.boxplot(data=train_df, x=variable, y='Pawpularity', ax=ax[0])\n    sns.histplot(train_df, x=\"Pawpularity\", hue=variable, kde=True, ax=ax[1])\n    plt.suptitle(variable, fontsize=20, fontweight='bold')\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:33:25.431785Z","iopub.execute_input":"2021-11-17T01:33:25.433946Z","iopub.status.idle":"2021-11-17T01:33:34.963747Z","shell.execute_reply.started":"2021-11-17T01:33:25.433909Z","shell.execute_reply":"2021-11-17T01:33:34.962870Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### As you can see from the charts, the distribution of pawpularity scores is very similar for each feature variable which means that changing the features doesn't end up influencing the pawpularity scores as much. This would mean that we would need to use the images and not the .csv metadata. This would've not been realized if it hadn't been for the EDA that was performed. We will focus on analyzing the pixels for the remainder of the baseline.","metadata":{}},{"cell_type":"markdown","source":"## Part II - Pixel EDA","metadata":{}},{"cell_type":"markdown","source":"### Before resizing the images to a uniform size, we have decided to explore the image data by taking a look at the first image in the train_jpg dataset and plotting that initial image:","metadata":{}},{"cell_type":"code","source":"print(train_jpg[0])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:21:12.642892Z","iopub.execute_input":"2021-11-17T01:21:12.643404Z","iopub.status.idle":"2021-11-17T01:21:12.651122Z","shell.execute_reply.started":"2021-11-17T01:21:12.643369Z","shell.execute_reply":"2021-11-17T01:21:12.650294Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"path_image = train_jpg[0]\narray_image = plt.imread(path_image) \nprint(array_image.shape)\n\nplt.imshow(array_image)\nplt.title('Initial Training Image') \nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:21:18.205650Z","iopub.execute_input":"2021-11-17T01:21:18.206497Z","iopub.status.idle":"2021-11-17T01:21:18.471309Z","shell.execute_reply.started":"2021-11-17T01:21:18.206432Z","shell.execute_reply":"2021-11-17T01:21:18.467471Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"### Next, we have attached a Pawpularity score as the title next to each image:","metadata":{}},{"cell_type":"code","source":"for x in range(3):\n    path_image = train_jpg[x]\n    array_image = plt.imread(path_image) \n    print(\"The image {}'s dimensions are: {}\".format(x,array_image.shape))\n    plt.imshow(array_image)\n    plt.title(x) \n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:21:34.085100Z","iopub.execute_input":"2021-11-17T01:21:34.085430Z","iopub.status.idle":"2021-11-17T01:21:34.989457Z","shell.execute_reply.started":"2021-11-17T01:21:34.085391Z","shell.execute_reply":"2021-11-17T01:21:34.988750Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### After gaining an initial sense of images looked, we have decided to start resizing the images to a uniform size. In this transformation, we also add white padding to images to help preserve image quality during the resizing.","metadata":{}},{"cell_type":"code","source":"## process in the training and test data, including the bw 1-d train data for baseline\n\ntrain_path = './train_resized'\ntrain_bw_path = './train_resized_bw'\ntest_path = './test'\n\ntrain_jpg = glob(train_path + \"/*.jpg\")\ntrain_bw_jpg = glob(train_bw_path + \"/*.jpg\")\ntest_jpg = glob(test_path + \"/*.jpg\")\n\n\ntrain_images = [cv2.imread(file) for file in train_jpg]\ntrain_bw_images_1d = [cv2.imread(file, 0).flatten(order = 'C') for file in train_bw_jpg] # 0 for grayscale, C for row-style flattening\ntest_images = [cv2.imread(file) for file in test_jpg]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:24:22.510370Z","iopub.execute_input":"2021-11-17T01:24:22.511090Z","iopub.status.idle":"2021-11-17T01:24:22.517461Z","shell.execute_reply.started":"2021-11-17T01:24:22.511040Z","shell.execute_reply":"2021-11-17T01:24:22.516803Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"X = np.array(train_bw_images_1d)\nX = X / 255\nY = np.array(train_df['Pawpularity'])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:24:05.807708Z","iopub.execute_input":"2021-11-17T01:24:05.807985Z","iopub.status.idle":"2021-11-17T01:24:05.814207Z","shell.execute_reply.started":"2021-11-17T01:24:05.807954Z","shell.execute_reply":"2021-11-17T01:24:05.811517Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:23:58.308771Z","iopub.execute_input":"2021-11-17T01:23:58.309047Z","iopub.status.idle":"2021-11-17T01:23:58.314714Z","shell.execute_reply.started":"2021-11-17T01:23:58.309015Z","shell.execute_reply":"2021-11-17T01:23:58.313938Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"### Examples of Transformed Images, Top Scoring Images, and Bottom Scoring Images:","metadata":{}},{"cell_type":"code","source":"#examples of transformed images\npltnum = 0\nplt.figure(figsize=(100,100))\n\nfor i in range(3):\n    pltnum += 1\n    plt.subplot(1, 3, pltnum)\n    plt.imshow(X[i].reshape(300,300), cmap='gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#examples of score = 100\n\ny_100 = np.where(Y == 100)\n\n\npltnum = 0\nplt.figure(figsize=(100,100))\n\nfor i in y_100[0][:3]:\n    pltnum += 1\n    plt.subplot(1, 3, pltnum)\n    plt.imshow(X[i].reshape(300,300), cmap='gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#example of scores in 75th percentile\ny_75quant = np.where(Y == np.percentile(Y, 75))\n\npltnum = 0\nplt.figure(figsize=(100,100))\n\nfor i in y_75quant[0][:3]:\n    pltnum += 1\n    plt.subplot(1, 3, pltnum)\n    plt.imshow(X[i].reshape(300,300), cmap='gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#example of scores in 25th percentile\ny_25quant = np.where(Y == np.percentile(Y, 25))\n\npltnum = 0\nplt.figure(figsize=(100,100))\n\nfor i in y_25quant[0][:3]:\n    pltnum += 1\n    plt.subplot(1, 3, pltnum)\n    plt.imshow(X[i].reshape(300,300), cmap='gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part III - Baseline Model","metadata":{}},{"cell_type":"code","source":"train_bw_images_1d, test_data, train_labels, test_labels = train_test_split(X,Y, test_size = .2, random_state = 42)\nprint(train_bw_images_1d.shape)\nprint(train_labels.shape)\nprint(test_data.shape)\nprint(test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:25:55.891216Z","iopub.execute_input":"2021-11-17T01:25:55.891475Z","iopub.status.idle":"2021-11-17T01:25:55.921125Z","shell.execute_reply.started":"2021-11-17T01:25:55.891447Z","shell.execute_reply":"2021-11-17T01:25:55.919949Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def get_image_model(img_size=Cfg.IMG_SIZE, n_channel=3):\n    \"\"\"\n    \"\"\"\n    inputs = layers.Input((img_size, img_size, n_channel))\n    x = inputs\n    \n    x = layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n    x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n    x = layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(x)\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu')(x)\n    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n    \n    x = layers.Flatten()(x)\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.Dropout(0.5)(x)\n    \n    outputs = x\n    model = keras.Model(\n        inputs=inputs, \n        outputs=outputs, \n        name='image_cnn_model')\n\n    return model    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### KNN Regression Model:","metadata":{}},{"cell_type":"code","source":"# Score RSME, especially where k = 9\n\ndef KNN(k_values):\n    for val in k_values:\n        KNN_model = KNeighborsRegressor(n_neighbors=val)\n        KNN_model.fit(train_bw_images_1d, train_labels)\n        test_predict = KNN_model.predict(test_data)\n        print(\"For k = \", val, \", the RMSE is: \", sqrt(mean_squared_error(test_labels, test_predict)), \"\\n\")\n        \nk_values = [1, 5, 9, 11, 55, 175, 201, 301, 501]\nKNN(k_values)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We observe the KNN regression produces optimized results for lowest RMSE between 201-301 neighbors (k = 201, RMSE = 21.006 and k = 301, RMSE = 21.0111). However, we can see the optimized RMSE is only slightly lower than when 9 neighbors are used (k = 9, RMSE = 21.901). Therefore we determine the benefits of the slightly lower RMSE are not worth the computing power of 200+ neighbors for our model. We will move forward with the k=9 KNN Regression model.","metadata":{}},{"cell_type":"markdown","source":"### Linear Regression Model:","metadata":{}},{"cell_type":"code","source":"# To comment out LRM\n\nlr_model = LinearRegression()\nlr_model.fit(train_bw_images_1d, train_labels)\nlr_model.intercept_, lr_model.coef_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_model.score(test_data, test_labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_predict = lr_model.predict(test_data)\nprint(\"LR RMSE is: \", sqrt(mean_squared_error(test_labels, lr_predict)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can observe the linear regression model performs poorly compared to the KNN models. We achieve an RMSE score of 31.681, much higher than any of the KNN models. Separately, we achieve a negative R squared score, which means the model's best-fit line fits worse than a horizontal line.\n\n### Based on these results, we will move forward with the KNN Regression with our baseline model. The RMSE for our baseline model is 21.901.\n\n### Our next steps will be to build a CNN model, which we hope will be able to better handle the complexity of the images and, in return, lower the RMSE.","metadata":{}},{"cell_type":"markdown","source":"### CNN Model:","metadata":{}},{"cell_type":"code","source":"# Setting the file path of each image\n\ntrain_df[\"path\"] = train_df[\"Id\"].apply(lambda x: \"../input/petfinder-pawpularity-score/train/\" + x + \".jpg\")\ntest_df[\"path\"] = test_df[\"Id\"].apply(lambda x: \"../input/petfinder-pawpularity-score/test/\" + x + \".jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:42:30.744970Z","iopub.execute_input":"2021-11-17T01:42:30.745242Z","iopub.status.idle":"2021-11-17T01:42:30.758321Z","shell.execute_reply.started":"2021-11-17T01:42:30.745211Z","shell.execute_reply":"2021-11-17T01:42:30.757451Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 64\nIMG_SIZE = 224\ntarget = 'Pawpularity'\nseed = 0\n\ndef set_seed(seed=seed):\n    \"\"\"Utility function to use for reproducibility.\n    :param seed: Random seed\n    :return: None\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\n\ndef set_display():\n    \"\"\"Function sets display options for charts and pd.DataFrames.\n    \"\"\"\n    # Plots display settings\n    plt.style.use('fivethirtyeight')\n    plt.rcParams['figure.figsize'] = 12, 8\n    plt.rcParams.update({'font.size': 14})\n    # DataFrame display settings\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_rows', None)\n    pd.options.display.float_format = '{:.4f}'.format\n\n\ndef id_to_path(img_id: str, dir: str):\n    \"\"\"Function returns a path to an image file.\n    :param img_id: Image Id\n    :param dir: Path to the directory with images\n    :return: Image file path\n    \"\"\"\n    return os.path.join(dir, f'{img_id}.jpg')\n\n\n@tf.function\ndef get_image(path: str) -> tf.Tensor:\n    \"\"\"Function loads image from a file and preprocesses it.\n    :param path: Path to image file\n    :return: Tensor with preprocessed image\n    \"\"\"\n    print(f\"IMAGE PROCESSING {str}\")\n    ## Decoding the image\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n\n    ## Resizing image\n    image = tf.cast(tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE), dtype=tf.int32)\n\n    return image\n\n\n@tf.function\ndef process_dataset(path: str, label: int) -> tuple:\n    \"\"\"Function returns preprocessed image and label.\n    :param path: Path to image file\n    :param label: Class label\n    :return: tf.Tensor with preprocessed image, numeric label\n    \"\"\"\n    return get_image(path), label\n\n\n@tf.function\ndef get_dataset(x, y=None) -> tf.data.Dataset:\n    \"\"\"Function creates batched optimized dataset for the model\n    out of an array of file paths and (optionally) class labels.\n    :param x: Input data for the model (array of file paths)\n    :param y: Target values for the model (array of class indexes)\n    :return TensorFlow Dataset object\n    \"\"\"\n    if y is not None:\n        ds = tf.data.Dataset.from_tensor_slices((x, y))\n        return ds.map(process_dataset, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices(x)\n        return ds.map(get_image, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\ndef plot_history(hist):\n    \"\"\"Function plots a chart with training and validation metrics.\n    :param hist: Tensorflow history object from model.fit()\n    \"\"\"\n    # Losses and metrics\n    loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n    rmse = hist.history['root_mean_squared_error']\n    val_rmse = hist.history['val_root_mean_squared_error']\n\n    # Epochs to plot along x axis\n    x_axis = range(1, len(loss) + 1)\n\n    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n\n    ax1.plot(x_axis, loss, 'bo', label='Training')\n    ax1.plot(x_axis, val_loss, 'ro', label='Validation', alpha=0.3)\n    ax1.set_title('MSE Loss')\n    ax1.legend()\n\n    ax2.plot(x_axis, rmse, 'bo', label='Training')\n    ax2.plot(x_axis, val_rmse, 'ro', label='Validation', alpha=0.3)\n    ax2.set_title('Root Mean Squared Error')\n    ax2.set_xlabel('Epochs')\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:42:32.746610Z","iopub.execute_input":"2021-11-17T01:42:32.746899Z","iopub.status.idle":"2021-11-17T01:42:32.764993Z","shell.execute_reply.started":"2021-11-17T01:42:32.746867Z","shell.execute_reply":"2021-11-17T01:42:32.764104Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Splitting train into train and validation sets\n\ntrain_subset, valid_subset = train_test_split(\n    train_df[['path', target]],\n    test_size=.2, shuffle=True, random_state=0\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:42:36.812330Z","iopub.execute_input":"2021-11-17T01:42:36.813051Z","iopub.status.idle":"2021-11-17T01:42:36.822698Z","shell.execute_reply.started":"2021-11-17T01:42:36.813011Z","shell.execute_reply":"2021-11-17T01:42:36.821882Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_ds = get_dataset(x=train_subset['path'], y=train_subset[target])\nvalid_ds = get_dataset(x=valid_subset['path'], y=valid_subset[target])\ntest_ds = get_dataset(x=test_df['path'])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:43:16.931983Z","iopub.execute_input":"2021-11-17T01:43:16.932629Z","iopub.status.idle":"2021-11-17T01:43:16.944990Z","shell.execute_reply.started":"2021-11-17T01:43:16.932579Z","shell.execute_reply":"2021-11-17T01:43:16.944062Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Creating the model\n\ndef get_model():\n    \n    ## Setting the Inputs\n    inputs = keras.Input(shape=(224, 224, 3))\n    x = inputs\n    \n    ## Preprocessing Layers\n    \n    ### Rescaling\n    x = keras.layers.experimental.preprocessing.Rescaling(1./255)(x)\n    \n    ## Data Augmentation\n    x = keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\")(x)\n    x = keras.layers.experimental.preprocessing.RandomRotation(0.2)(x)\n    x = keras.layers.experimental.preprocessing.RandomTranslation(0.2,0.2)(x)\n    \n    ## Convolutional Layers\n    \n    ### First CNN layer\n    x = keras.layers.Conv2D(filters=96, kernel_size=3, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.MaxPool2D(2)(x)\n\n    ### Second CNN layer\n    x = keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.MaxPool2D(2)(x)\n    \n    ### Third CNN layer\n    x = keras.layers.Conv2D(filters=256, kernel_size=3, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.MaxPool2D(2)(x)\n\n    ## Flattening the layer\n    x = keras.layers.Flatten()(x)\n    \n    ## Fully Connected (Dense) Layers\n    \n    ### First Fully Connected layer w/ Dropout\n    x = keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal())(x)\n    x = keras.layers.Dropout(0.2)(x)\n    \n    ## Output layer\n    output = keras.layers.Dense(1)(x)\n\n    ## Returning the model\n    return keras.Model(inputs=inputs, outputs=output)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:43:21.875185Z","iopub.execute_input":"2021-11-17T01:43:21.875737Z","iopub.status.idle":"2021-11-17T01:43:21.888089Z","shell.execute_reply.started":"2021-11-17T01:43:21.875697Z","shell.execute_reply":"2021-11-17T01:43:21.887201Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\n\ndef compile_and_fit(model):\n    \n    # Creating an exponential decay for learning rate\n\n    LEARNING_RATE = 1e-2\n    DECAY_STEPS = 100\n    DECAY_RATE = 0.99\n\n    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=LEARNING_RATE,\n        decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE,\n        staircase=True\n    )\n    \n    # Creating an early stopper\n\n    early_stop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss', patience=5, restore_best_weights=True\n    )\n    \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n        loss=tf.keras.losses.MeanSquaredError(),\n        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n    )\n    \n    history = model.fit(\n        train_ds, \n        validation_data=valid_ds,\n        epochs=50,\n        use_multiprocessing=True, workers=-1,\n        callbacks=[early_stop]\n    )\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:43:24.906608Z","iopub.execute_input":"2021-11-17T01:43:24.907149Z","iopub.status.idle":"2021-11-17T01:43:24.914961Z","shell.execute_reply.started":"2021-11-17T01:43:24.907109Z","shell.execute_reply":"2021-11-17T01:43:24.914242Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Getting the model\n\nkeras.backend.clear_session()\n\nmodel = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:43:31.312604Z","iopub.execute_input":"2021-11-17T01:43:31.313266Z","iopub.status.idle":"2021-11-17T01:43:31.545847Z","shell.execute_reply.started":"2021-11-17T01:43:31.313228Z","shell.execute_reply":"2021-11-17T01:43:31.545078Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\n\nmodel, history = compile_and_fit(model)\n# predictions = model.predict(valid_ds, use_multiprocessing=True, workers=os.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2021-11-17T01:43:40.136842Z","iopub.execute_input":"2021-11-17T01:43:40.137119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting accuracy and loss of model\n\nplot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the model to predict on the test data\n\ntest_df[target] = model.predict(\n    test_ds, use_multiprocessing=True, workers=os.cpu_count()\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the submission file\n\ntest_df[['Id', target]].to_csv('submission.csv', index=False)\ntest_df[['Id', target]].head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#binning columns to test models\ntrain['two_bin_pawp'] = pd.qcut(train_df['Pawpularity'], q=2, labels=False)\ntrain = train.astype({\"two_bin_pawp\": str})\n\ntrain['four_bin_pawp'] = pd.qcut(train_df['Pawpularity'], q=4, labels=False)\ntrain = train.astype({\"four_bin_pawp\": str})\n\ntrain['ten_bin_pawp'] = pd.qcut(train_df['Pawpularity'], q=10, labels=False)\ntrain = train.astype({\"ten_bin_pawp\": str})","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}