{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mount Google drive to upload datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMX3q05w9e3c",
        "outputId": "104c1e91-a0bf-4520-a358-774cb0b8f6d2"
      },
      "id": "mMX3q05w9e3c",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJTrcX51meDb",
        "outputId": "acf0862e-11e2-44ff-d911-868e0734ec4a"
      },
      "id": "pJTrcX51meDb",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoPU3BPY9xeA",
        "outputId": "f87a888f-33d4-413d-f722-e961d000844c"
      },
      "id": "eoPU3BPY9xeA",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281.3 MB 43 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199 kB 47.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=a941aa2cc51f1caebaf8de70701397e0b9f8455836fe03d8d24b96f93d2129dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "ghFoc5BW914v"
      },
      "id": "ghFoc5BW914v",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "thlUYHXT94x-"
      },
      "id": "thlUYHXT94x-",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "                    .master('local')\\\n",
        "                    .appName('Colab')\\\n",
        "                    .config('spark.ui.port', '4050')\\\n",
        "                    .getOrCreate()"
      ],
      "metadata": {
        "id": "mHvOatYm97EL"
      },
      "id": "mHvOatYm97EL",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chIUZrMH_Aod",
        "outputId": "d59f000a-a566-4517-881b-edcfcbcbbc78"
      },
      "id": "chIUZrMH_Aod",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qr 'requirements.txt'"
      ],
      "metadata": {
        "id": "folhFVy1_DzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1903d1f-c3c7-4981-d95e-ca00c568ae91"
      },
      "id": "folhFVy1_DzL",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |â–Œ                               | 10 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |â–ˆ                               | 20 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–‹                              | 30 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–                             | 40 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–Š                             | 51 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–Ž                            | 61 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–‰                            | 71 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 81 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 92 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 102 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 112 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 122 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 133 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 143 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 153 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 163 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 174 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 184 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 194 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 204 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 215 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 225 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 235 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 245 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 256 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 266 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                 | 276 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 286 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 296 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 307 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 317 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 327 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 337 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 348 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 358 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 368 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 378 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 389 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 399 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 409 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 419 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 430 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 440 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 450 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 460 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 471 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 481 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 491 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 501 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 512 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 522 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 532 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 542 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 552 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 563 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 573 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 583 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 593 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 6.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhGVPQ9R_Jda",
        "outputId": "c8dc5ef1-752a-49f8-8162-2ecf21da931f"
      },
      "id": "AhGVPQ9R_Jda",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "92d94691",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "92d94691"
      },
      "outputs": [],
      "source": [
        "# Databricks notebook source\n",
        "import torch\n",
        "from PIL import Image\n",
        "import glob\n",
        "import pandas as pd\n",
        "from typing import Iterator, Tuple\n",
        "import uuid\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets.folder import default_loader\n",
        "from pyspark.sql.functions import col, pandas_udf\n",
        "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
        "from pyspark.sql.functions import when, col, udf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a3340454",
      "metadata": {
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3340454",
        "outputId": "396150d2-3dc5-408e-9b3b-31d3f1612b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m PyYAML>=5.3.1 not found and is required by YOLOv5, attempting auto-update...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /root/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 ðŸš€ 2022-7-29 Python-3.7.13 torch-1.12.0+cu113 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
            "\n",
            "Loading /content/drive/MyDrive/yolov5/yolov_runs/frozen_w_coco_unlabeled2/weights/frozen_backbone_coco_unlabeled_best.onnx for ONNX Runtime inference...\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m onnx not found and is required by YOLOv5, attempting auto-update...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.12.2->onnx) (1.15.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.12.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m onnxruntime-gpu not found and is required by YOLOv5, attempting auto-update...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111.0 MB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (1.7.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (21.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (1.21.6)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->onnxruntime-gpu) (3.0.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime-gpu) (1.15.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->onnxruntime-gpu) (1.2.1)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.12.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 2 packages updated per ['onnx', 'onnxruntime-gpu']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'custom', \n",
        "                       '/content/drive/MyDrive/yolov5/yolov_runs/frozen_w_coco_unlabeled2/weights/frozen_backbone_coco_unlabeled_best.onnx',\n",
        "                       trust_repo=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "71e8a9e5",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "71e8a9e5"
      },
      "outputs": [],
      "source": [
        "def yolov_preds(img_paths, model):\n",
        "    \"\"\"Accepts a string of image paths and returns the Yolov predicted fields\"\"\"\n",
        "    \n",
        "    # Load the trained model\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    \n",
        "    # Create lists to hold the path and the Yolov fields\n",
        "    failed = []\n",
        "    processed = []\n",
        "    yolo_xmin = []\n",
        "    yolo_ymin = []\n",
        "    yolo_xmax = []\n",
        "    yolo_ymax = []\n",
        "    yolo_confidence = []\n",
        "    yolo_bb_classes = []\n",
        "    yolo_names = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for f in img_paths:\n",
        "            img = Image.open(f)\n",
        "            results = model(img, size=640)\n",
        "            df = results.pandas().xyxy[0]\n",
        "            bbs_det = len(df)\n",
        "            \n",
        "            if bbs_det == 0:\n",
        "                failed.append(f)\n",
        "            \n",
        "            if bbs_det > 0:\n",
        "                # Add the path to the img paths by a multiplier so that it's added multiple times if multiple bounding boxes are produced\n",
        "                processed.extend([f for x in range(bbs_det)])\n",
        "            \n",
        "                # Make dataframes of the Yolov fields from the detection\n",
        "                xmin = df.xmin.tolist()\n",
        "                ymin = df.ymin.tolist()\n",
        "                xmax = df.xmax.tolist()\n",
        "                ymax = df.ymax.tolist()\n",
        "                confidence = df.confidence.tolist()\n",
        "                bb_classes = df['class'].tolist()\n",
        "                names = df.name.tolist()\n",
        "            \n",
        "                # Add the values to their respective lists\n",
        "                yolo_xmin.extend(xmin)\n",
        "                yolo_ymin.extend(ymin)\n",
        "                yolo_xmax.extend(xmax)\n",
        "                yolo_ymax.extend(ymax)\n",
        "                yolo_confidence.extend(confidence)\n",
        "                yolo_bb_classes.extend(bb_classes)\n",
        "                yolo_names.extend(names)\n",
        "            \n",
        "    return failed, pd.DataFrame({\n",
        "        'img_path': processed,\n",
        "        'xmin': yolo_xmin,\n",
        "        'ymin':yolo_ymin,\n",
        "        'xmax': yolo_xmax,\n",
        "        'ymax': yolo_ymax,\n",
        "        'confidence': yolo_confidence,\n",
        "        'bb_class': yolo_bb_classes,\n",
        "        'names': yolo_names,\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D = '/content/drive/MyDrive'"
      ],
      "metadata": {
        "id": "ITFMSFZO_r3M"
      },
      "id": "ITFMSFZO_r3M",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2fdf8cee",
      "metadata": {
        "id": "2fdf8cee"
      },
      "outputs": [],
      "source": [
        "# Pass the list of images to the Yolov model and generate the Yolov predictions\n",
        "imgs = glob.glob(D+'/yolov5/customdata/images/test/*.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b6019e93",
      "metadata": {
        "id": "b6019e93"
      },
      "outputs": [],
      "source": [
        "# Create a dataframe from the predictions\n",
        "failed_preds, yolo_test_preds = yolov_preds(imgs, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "917ff64c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "917ff64c",
        "outputId": "8a2d3785-d849-4bab-e55e-269991a59703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25 images failed to produce a prediction, out of 1033 total images\n"
          ]
        }
      ],
      "source": [
        "# Find the number of images where a prediction failed to be made\n",
        "print(f'{len(failed_preds)} images failed to produce a prediction, out of {len(imgs)} total images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "59fe8311",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "59fe8311",
        "outputId": "23ac9f7c-fdb5-4f0c-c7ff-12e87d0048c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            img_path        xmin        ymin  \\\n",
              "0  /content/drive/MyDrive/yolov5/customdata/image...  105.752777   60.255127   \n",
              "1  /content/drive/MyDrive/yolov5/customdata/image...  299.829956  220.644257   \n",
              "2  /content/drive/MyDrive/yolov5/customdata/image...  187.540527  236.484894   \n",
              "3  /content/drive/MyDrive/yolov5/customdata/image...   23.572754    0.000000   \n",
              "4  /content/drive/MyDrive/yolov5/customdata/image...  238.281403  206.198959   \n",
              "\n",
              "         xmax        ymax  confidence  bb_class                  names  \n",
              "0  378.000244  610.764404    0.768734         0  Giraffa_tippelskirchi  \n",
              "1  431.216553  362.138153    0.876029         0  Giraffa_tippelskirchi  \n",
              "2  248.498108  362.121307    0.527206         0  Giraffa_tippelskirchi  \n",
              "3  634.253723  570.580444    0.331881         0  Giraffa_tippelskirchi  \n",
              "4  630.858032  638.992126    0.724897         0  Giraffa_tippelskirchi  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c252e23-6d44-43be-95d4-5546b44eedd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_path</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "      <th>confidence</th>\n",
              "      <th>bb_class</th>\n",
              "      <th>names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/yolov5/customdata/image...</td>\n",
              "      <td>105.752777</td>\n",
              "      <td>60.255127</td>\n",
              "      <td>378.000244</td>\n",
              "      <td>610.764404</td>\n",
              "      <td>0.768734</td>\n",
              "      <td>0</td>\n",
              "      <td>Giraffa_tippelskirchi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/yolov5/customdata/image...</td>\n",
              "      <td>299.829956</td>\n",
              "      <td>220.644257</td>\n",
              "      <td>431.216553</td>\n",
              "      <td>362.138153</td>\n",
              "      <td>0.876029</td>\n",
              "      <td>0</td>\n",
              "      <td>Giraffa_tippelskirchi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/yolov5/customdata/image...</td>\n",
              "      <td>187.540527</td>\n",
              "      <td>236.484894</td>\n",
              "      <td>248.498108</td>\n",
              "      <td>362.121307</td>\n",
              "      <td>0.527206</td>\n",
              "      <td>0</td>\n",
              "      <td>Giraffa_tippelskirchi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/yolov5/customdata/image...</td>\n",
              "      <td>23.572754</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>634.253723</td>\n",
              "      <td>570.580444</td>\n",
              "      <td>0.331881</td>\n",
              "      <td>0</td>\n",
              "      <td>Giraffa_tippelskirchi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/yolov5/customdata/image...</td>\n",
              "      <td>238.281403</td>\n",
              "      <td>206.198959</td>\n",
              "      <td>630.858032</td>\n",
              "      <td>638.992126</td>\n",
              "      <td>0.724897</td>\n",
              "      <td>0</td>\n",
              "      <td>Giraffa_tippelskirchi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c252e23-6d44-43be-95d4-5546b44eedd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c252e23-6d44-43be-95d4-5546b44eedd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c252e23-6d44-43be-95d4-5546b44eedd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Check the first few rows of the yolo val preds dataframe\n",
        "yolo_test_preds.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5825845c",
      "metadata": {
        "id": "5825845c"
      },
      "outputs": [],
      "source": [
        "# Convert the Pandas dataframe to PySpark for assessment\n",
        "spark_yolo_test = spark.createDataFrame(yolo_test_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4e7d51cc",
      "metadata": {
        "id": "4e7d51cc"
      },
      "outputs": [],
      "source": [
        "# Add a column for what the true label of the animal in the photo is\n",
        "spark_yolo_test = spark_yolo_test.withColumn('true_img_label', when(col('img_path').contains('giraffe'), 'Giraffa_tippelskirchi')\n",
        "                                                             .when(col('img_path').contains('hyena'), 'Crocuta_crocuta')\n",
        "                                                             .otherwise('Panthera_pardus'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1576b5fd",
      "metadata": {
        "id": "1576b5fd"
      },
      "outputs": [],
      "source": [
        "# Find the count of bounding boxes predicted where the predicted label didn't match what was in the image\n",
        "incorrect_bbs = spark_yolo_test.filter(col('names') != col('true_img_label'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1447134e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1447134e",
        "outputId": "ce531d85-a6cb-478b-de18-9672b77e5b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 9 incorrect bounding boxes predicted\n"
          ]
        }
      ],
      "source": [
        "print(f'There were {incorrect_bbs.count()} incorrect bounding boxes predicted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "669f0c53",
      "metadata": {
        "id": "669f0c53"
      },
      "outputs": [],
      "source": [
        "# Find the number of unique images where an incorrect bounding box was predicted\n",
        "incorrect_imgs = incorrect_bbs.select('img_path').distinct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f29aca8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f29aca8a",
        "outputId": "c898ac4d-6160-4506-8bf9-ed2308d32a0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 9 images where an incorrect bounding box was predicted\n"
          ]
        }
      ],
      "source": [
        "print(f'There were {incorrect_imgs.count()} images where an incorrect bounding box was predicted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "5adac925",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5adac925",
        "outputId": "3517d5e4-b168-43dc-afb8-50ec10dcd093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 1073 correct bounding boxes predicted\n",
            "There were 1007 images with at least 1 correct bounding box\n"
          ]
        }
      ],
      "source": [
        "# Find the number of correct bounding boxes\n",
        "correct_bbs = spark_yolo_test.filter(col('names') == col('true_img_label'))\n",
        "print(f'There were {correct_bbs.count()} correct bounding boxes predicted')\n",
        "correct_imgs = correct_bbs.select('img_path').distinct()\n",
        "print(f'There were {correct_imgs.count()} images with at least 1 correct bounding box')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d36e0ad8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d36e0ad8",
        "outputId": "f54ba7d0-c2bf-4d07-c6cd-c4f501beefad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 1065 bounding boxes predicted for images where all of the predictions were correct\n",
            "There were 999 images where all of the predicted bounding boxes were correct\n"
          ]
        }
      ],
      "source": [
        "# Now, let's look at the images where all of the bounding boxes were correct\n",
        "all_correct = correct_bbs.join(incorrect_bbs, correct_bbs.img_path == incorrect_bbs.img_path, how='left_anti')\n",
        "print(f'There were {all_correct.count()} bounding boxes predicted for images where all of the predictions were correct')\n",
        "all_correct_imgs = all_correct.select('img_path').distinct()\n",
        "print(f'There were {all_correct_imgs.count()} images where all of the predicted bounding boxes were correct')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1583d9a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1583d9a5",
        "outputId": "3dfd22d5-1b49-45a0-dc46-259eeed2a609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 images failed to produce a prediction, out of 338 total hyena images, or 25 total failed images\n"
          ]
        }
      ],
      "source": [
        "# Filter the dataframe to hyena images and repeat the assessment of images where a prediction failed to be made and correct vs incorrect predictions\n",
        "failed_df = spark.createDataFrame(failed_preds, StringType())\n",
        "failed_df = failed_df.withColumnRenamed('value', 'img_path')\n",
        "failed_df = failed_df.withColumn('true_img_label', when(col('img_path').contains('giraffe'), 'Giraffa_tippelskirchi')\n",
        "                                                             .when(col('img_path').contains('hyena'), 'Crocuta_crocuta')\n",
        "                                                             .otherwise('Panthera_pardus'))\n",
        "hyena_failed = failed_df.filter(col('true_img_label') == 'Crocuta_crocuta')\n",
        "hyena_predicted = spark_yolo_test.filter(col('true_img_label') == 'Crocuta_crocuta')\n",
        "print(f'{hyena_failed.count()} images failed to produce a prediction, out of {hyena_predicted.count() + hyena_failed.count()} total hyena images, or {failed_df.count()} total failed images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "e7a0542c",
      "metadata": {
        "id": "e7a0542c"
      },
      "outputs": [],
      "source": [
        "# Find the count of bounding boxes predicted where the predicted label didn't match what was in the image\n",
        "hyena_incorrect_bbs = hyena_predicted.filter(col('names') != col('true_img_label'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "362f3c37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "362f3c37",
        "outputId": "ed0ecb8d-73bf-44ab-e1f7-649b746fec37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 4 incorrect bounding boxes predicted\n"
          ]
        }
      ],
      "source": [
        "print(f'There were {hyena_incorrect_bbs.count()} incorrect bounding boxes predicted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "672a34ac",
      "metadata": {
        "id": "672a34ac"
      },
      "outputs": [],
      "source": [
        "# Find the number of unique images where an incorrect bounding box was predicted\n",
        "hyena_incorrect_imgs = hyena_incorrect_bbs.select('img_path').distinct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "8267ee26",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8267ee26",
        "outputId": "28aea290-4f6a-4cf6-c705-a913a901eee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 4 images where an incorrect bounding box was predicted\n"
          ]
        }
      ],
      "source": [
        "print(f'There were {hyena_incorrect_imgs.count()} images where an incorrect bounding box was predicted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "3927a3b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3927a3b1",
        "outputId": "1f1998a3-d386-468a-f78c-674063528cb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 330 correct bounding boxes predicted\n",
            "There were 305 images with at least 1 correct bounding box\n"
          ]
        }
      ],
      "source": [
        "# Find the number of correct bounding boxes\n",
        "hyena_correct_bbs = hyena_predicted.filter(col('names') == col('true_img_label'))\n",
        "print(f'There were {hyena_correct_bbs.count()} correct bounding boxes predicted')\n",
        "hyena_correct_imgs = hyena_correct_bbs.select('img_path').distinct()\n",
        "print(f'There were {hyena_correct_imgs.count()} images with at least 1 correct bounding box')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "b7ed4288",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7ed4288",
        "outputId": "1e4b5645-b0da-4e98-fbb6-bf3fa48375fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 326 bounding boxes predicted for images where all of the predictions were correct\n",
            "There were 301 images where all of the predicted bounding boxes were correct\n"
          ]
        }
      ],
      "source": [
        "# Now, let's look at the images where all of the bounding boxes were correct\n",
        "hyena_all_correct = hyena_correct_bbs.join(hyena_incorrect_bbs, hyena_correct_bbs.img_path == hyena_incorrect_bbs.img_path, how='left_anti')\n",
        "print(f'There were {hyena_all_correct.count()} bounding boxes predicted for images where all of the predictions were correct')\n",
        "hyena_all_correct_imgs = hyena_all_correct.select('img_path').distinct()\n",
        "print(f'There were {hyena_all_correct_imgs.count()} images where all of the predicted bounding boxes were correct')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d85094be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d85094be",
        "outputId": "7da688e3-df3e-4eef-987b-2b3781ad5bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17 images failed to produce a prediction, out of 698 total leopard images, or 25 total failed images\n"
          ]
        }
      ],
      "source": [
        "# Filter the dataframe to leopard images and repeat the assessment of images where a prediction failed to be made and correct vs incorrect predictions\n",
        "leopard_failed = failed_df.filter(col('true_img_label') == 'Panthera_pardus')\n",
        "leopard_predicted = spark_yolo_test.filter(col('true_img_label') == 'Panthera_pardus')\n",
        "print(f'{leopard_failed.count()} images failed to produce a prediction, out of {leopard_predicted.count() + leopard_failed.count()} total leopard images, or {failed_df.count()} total failed images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "98d2d8c9",
      "metadata": {
        "id": "98d2d8c9"
      },
      "outputs": [],
      "source": [
        "# Find the count of bounding boxes predicted where the predicted label didn't match what was in the image\n",
        "leopard_incorrect_bbs = leopard_predicted.filter(col('names') != col('true_img_label'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "b9f06ad6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9f06ad6",
        "outputId": "be98fb9f-43fb-4c49-9cd0-d304db35463c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 5 incorrect bounding boxes predicted\n"
          ]
        }
      ],
      "source": [
        "print(f'There were {leopard_incorrect_bbs.count()} incorrect bounding boxes predicted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "d4054951",
      "metadata": {
        "id": "d4054951"
      },
      "outputs": [],
      "source": [
        "# Find the number of unique images where an incorrect bounding box was predicted\n",
        "leopard_incorrect_imgs = leopard_incorrect_bbs.select('img_path').distinct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "7200408c",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7200408c",
        "outputId": "47932688-c91c-4e07-8735-d5db77f755d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 5 images where an incorrect bounding box was predicted\n"
          ]
        }
      ],
      "source": [
        "print(f'There were {leopard_incorrect_imgs.count()} images where an incorrect bounding box was predicted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "e66d42cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e66d42cb",
        "outputId": "e4c40215-de04-4bb8-edb7-387cea7d6046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 676 correct bounding boxes predicted\n",
            "There were 655 images with at least 1 correct bounding box\n"
          ]
        }
      ],
      "source": [
        "# Find the number of correct bounding boxes\n",
        "leopard_correct_bbs = leopard_predicted.filter(col('names') == col('true_img_label'))\n",
        "print(f'There were {leopard_correct_bbs.count()} correct bounding boxes predicted')\n",
        "leopard_correct_imgs = leopard_correct_bbs.select('img_path').distinct()\n",
        "print(f'There were {leopard_correct_imgs.count()} images with at least 1 correct bounding box')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "7c7a3c7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c7a3c7e",
        "outputId": "ee7bf8b3-0bf5-4d70-ef8b-02b05bc779ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 672 bounding boxes predicted for images where all of the predictions were correct\n",
            "There were 651 images where all of the predicted bounding boxes were correct\n"
          ]
        }
      ],
      "source": [
        "# Now, let's look at the images where all of the bounding boxes were correct\n",
        "leopard_all_correct = leopard_correct_bbs.join(leopard_incorrect_bbs, leopard_correct_bbs.img_path == leopard_incorrect_bbs.img_path, how='left_anti')\n",
        "print(f'There were {leopard_all_correct.count()} bounding boxes predicted for images where all of the predictions were correct')\n",
        "leopard_all_correct_imgs = leopard_all_correct.select('img_path').distinct()\n",
        "print(f'There were {leopard_all_correct_imgs.count()} images where all of the predicted bounding boxes were correct')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "284f322c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "284f322c",
        "outputId": "249bc34a-c806-4e77-d15e-c64978053154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 images failed to produce a prediction, out of 71 total giraffe images, or 25 total failed images\n"
          ]
        }
      ],
      "source": [
        "# Filter the dataframe to leopard images and repeat the assessment of images where a prediction failed to be made and correct vs incorrect predictions\n",
        "giraffe_failed = failed_df.filter(col('true_img_label') == 'Giraffa_tippelskirchi')\n",
        "giraffe_predicted = spark_yolo_test.filter(col('true_img_label') == 'Giraffa_tippelskirchi')\n",
        "print(f'{giraffe_failed.count()} images failed to produce a prediction, out of {giraffe_predicted.count() + giraffe_failed.count()} total giraffe images, or {failed_df.count()} total failed images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "ebb49ab7",
      "metadata": {
        "id": "ebb49ab7"
      },
      "outputs": [],
      "source": [
        "# Find the count of bounding boxes predicted where the predicted label didn't match what was in the image\n",
        "giraffe_incorrect_bbs = giraffe_predicted.filter(col('names') != col('true_img_label'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "e1751630",
      "metadata": {
        "id": "e1751630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ee8969-ae67-449f-e78f-61895f9b7e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 0 incorrect bounding boxes predicted\n"
          ]
        }
      ],
      "source": [
        "print(f'There were {giraffe_incorrect_bbs.count()} incorrect bounding boxes predicted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "cb38389c",
      "metadata": {
        "id": "cb38389c"
      },
      "outputs": [],
      "source": [
        "# Find the number of unique images where an incorrect bounding box was predicted\n",
        "giraffe_incorrect_imgs = giraffe_incorrect_bbs.select('img_path').distinct()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "13f3fadb",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13f3fadb",
        "outputId": "51bd5575-4a65-4013-bfc1-c7478477dbaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 0 images where an incorrect bounding box was predicted\n"
          ]
        }
      ],
      "source": [
        "print(f'There were {giraffe_incorrect_imgs.count()} images where an incorrect bounding box was predicted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "4b5f9195",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b5f9195",
        "outputId": "20a76006-24f8-401f-dd98-ad8085e9d718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 67 correct bounding boxes predicted\n",
            "There were 47 images with at least 1 correct bounding box\n"
          ]
        }
      ],
      "source": [
        "# Find the number of correct bounding boxes\n",
        "giraffe_correct_bbs = giraffe_predicted.filter(col('names') == col('true_img_label'))\n",
        "print(f'There were {giraffe_correct_bbs.count()} correct bounding boxes predicted')\n",
        "giraffe_correct_imgs = giraffe_correct_bbs.select('img_path').distinct()\n",
        "print(f'There were {giraffe_correct_imgs.count()} images with at least 1 correct bounding box')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "adaac776",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adaac776",
        "outputId": "729f9e8c-07d0-44ee-de9f-557ecfe9032b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There were 67 bounding boxes predicted for images where all of the predictions were correct\n",
            "There were 47 images where all of the predicted bounding boxes were correct\n"
          ]
        }
      ],
      "source": [
        "# Now, let's look at the images where all of the bounding boxes were correct\n",
        "giraffe_all_correct = giraffe_correct_bbs.join(giraffe_incorrect_bbs, giraffe_correct_bbs.img_path == giraffe_incorrect_bbs.img_path, how='left_anti')\n",
        "print(f'There were {giraffe_all_correct.count()} bounding boxes predicted for images where all of the predictions were correct')\n",
        "giraffe_all_correct_imgs = giraffe_all_correct.select('img_path').distinct()\n",
        "print(f'There were {giraffe_all_correct_imgs.count()} images where all of the predicted bounding boxes were correct')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "24143af9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24143af9",
        "outputId": "fbaf5dec-742d-4414-d19a-434d2a295133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+---------------------+-----+\n",
            "|true_img_label       |names                |count|\n",
            "+---------------------+---------------------+-----+\n",
            "|Crocuta_crocuta      |Panthera_pardus      |4    |\n",
            "|Panthera_pardus      |Panthera_pardus      |676  |\n",
            "|Giraffa_tippelskirchi|Giraffa_tippelskirchi|67   |\n",
            "|Crocuta_crocuta      |Crocuta_crocuta      |330  |\n",
            "|Panthera_pardus      |Crocuta_crocuta      |5    |\n",
            "+---------------------+---------------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show the counts of \n",
        "combos = spark_yolo_test.groupby('true_img_label', 'names').count()\n",
        "combos.show(20, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "c29afc42",
      "metadata": {
        "id": "c29afc42"
      },
      "outputs": [],
      "source": [
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.sql.types import DoubleType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "2f3d405d",
      "metadata": {
        "id": "2f3d405d"
      },
      "outputs": [],
      "source": [
        "spark_yolo_test = spark_yolo_test.withColumn('prediction', when(col('names') == 'Crocuta_crocuta', lit(0))\n",
        "                                                             .when(col('names') == 'Panthera_pardus', lit(1))\n",
        "                                                             .otherwise(lit(2)))\n",
        "spark_yolo_test = spark_yolo_test.withColumn('label', when(col('true_img_label') == 'Crocuta_crocuta', lit(0))\n",
        "                                                             .when(col('true_img_label') == 'Panthera_pardus', lit(1))\n",
        "                                                             .otherwise(lit(2)))\n",
        "spark_yolo_test = spark_yolo_test.withColumn('prediction', col('prediction').cast(DoubleType())).withColumn('label', col('label').cast(DoubleType()))\n",
        "check = spark_yolo_test.select('prediction', 'label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "e943ffce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e943ffce",
        "outputId": "02a86ea2-e752-4b85-a020-48b8e4f3cc35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9916852311137159\n",
            "0.9916904279299382\n",
            "0.9916820702402958\n"
          ]
        }
      ],
      "source": [
        "evaluator = MulticlassClassificationEvaluator()\n",
        "evaluator.setPredictionCol('prediction')\n",
        "print(f'Accuracy: {evaluator.evaluate(check)}')\n",
        "print(evaluator.evaluate(check, {evaluator.metricName: 'weightedPrecision'}))\n",
        "print(evaluator.evaluate(check, {evaluator.metricName: 'weightedRecall'}))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the accuracy, recall, and precision by species\n",
        "hyena_check = check.filter(col('label') == 0)\n",
        "leopard_check = check.filter(col('label') == 1)\n",
        "giraffe_check = check.filter(col('label') == 2)\n",
        "\n",
        "print(f'Hyena accuracy: {evaluator.evaluate(hyena_check)}')\n",
        "print(f'Leopard accuracy: {evaluator.evaluate(leopard_check)}')\n",
        "print(f'Giraffe accuracy: {evaluator.evaluate(giraffe_check)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0sgC3PgEM60",
        "outputId": "ba3827b1-fa72-440d-9121-a93fdd5c5507"
      },
      "id": "X0sgC3PgEM60",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyena accuracy: 0.9939759036144579\n",
            "Leopard accuracy: 0.9963154016212233\n",
            "Giraffe accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "pd_check = check.toPandas()"
      ],
      "metadata": {
        "id": "x8ZDe56QGZF5"
      },
      "id": "x8ZDe56QGZF5",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Class precision scores: {precision_score(pd_check.label, pd_check.prediction, average=None)}')\n",
        "print(f'Class recall scores: {recall_score(pd_check.label, pd_check.prediction, average=None)}')\n",
        "print(f'Class f1 scores: {f1_score(pd_check.label, pd_check.prediction, average=None)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2hrVWD4GunW",
        "outputId": "db438033-d5d3-4f4a-9925-4e1252b6f14b"
      },
      "id": "i2hrVWD4GunW",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class precision scores: [    0.98507     0.99412           1]\n",
            "Class recall scores: [    0.98802     0.99266           1]\n",
            "Class f1 scores: [    0.98655     0.99339           1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "1f81cf4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f81cf4f",
        "outputId": "d01a0964-3cdc-49e7-e9b3-b78ceebf7625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9850746268656716\n",
            "0.9880239520958084\n"
          ]
        }
      ],
      "source": [
        "print(evaluator.evaluate(check, {evaluator.metricName: 'precisionByLabel'}))\n",
        "print(evaluator.evaluate(check, {evaluator.metricName: 'recallByLabel'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "5bceeb32",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "5bceeb32"
      },
      "outputs": [],
      "source": [
        "def scale_yolo(xmin, ymin, xmax, ymax):\n",
        "    \"\"\"Create a scaled version of the predicted bounding boxes\"\"\"\n",
        "    x = xmin/640\n",
        "    y = ymin/640\n",
        "    w = (xmax - xmin)/640\n",
        "    h = (ymax - ymin)/640\n",
        "    return [x, y, w, h]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "d35cb032",
      "metadata": {
        "id": "d35cb032"
      },
      "outputs": [],
      "source": [
        "def convert_nonnormalized(xmin, ymin, xmax, ymax):\n",
        "    \"\"\"Converts predicted bounding box values to Coco format\"\"\"\n",
        "    return [xmin, ymin, xmax-xmin, ymax-ymin]\n",
        "scale_yolo_udf = udf(scale_yolo)\n",
        "coco_nonnormalized_udf = udf(convert_nonnormalized)\n",
        "spark_yolo_test = spark_yolo_test.withColumn('yolo_scaled_bxs', scale_yolo_udf(spark_yolo_test.xmin, spark_yolo_test.ymin, spark_yolo_test.xmax, spark_yolo_test.ymax))\n",
        "spark_yolo_test = spark_yolo_test.withColumn('nonscaled_coco_bxs', coco_nonnormalized_udf(spark_yolo_test.xmin, spark_yolo_test.ymin, spark_yolo_test.xmax, spark_yolo_test.ymax))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "dfdcedb5",
      "metadata": {
        "id": "dfdcedb5"
      },
      "outputs": [],
      "source": [
        "# Create a custom UDF to cast lists as arrays\n",
        "udf_array = udf(lambda row: list(row), ArrayType(FloatType()))\n",
        "spark_yolo_val = spark_yolo_test.withColumn('nonscaled_coco_bxs', udf_array(spark_yolo_test.nonscaled_coco_bxs)).withColumn('yolo_scaled_bxs', udf_array(spark_yolo_test.yolo_scaled_bxs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "038e5df2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "038e5df2",
        "outputId": "b8a7e306-ed62-4eb1-d118-f4380260bae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------+------------------+------------------+------------------+------------------+------------------+--------+---------------------+---------------------+----------+-----+-------------------------------------------------+--------------------------------------------+\n",
            "|img_path                                                             |xmin              |ymin              |xmax              |ymax              |confidence        |bb_class|names                |true_img_label       |prediction|label|yolo_scaled_bxs                                  |nonscaled_coco_bxs                          |\n",
            "+---------------------------------------------------------------------+------------------+------------------+------------------+------------------+------------------+--------+---------------------+---------------------+----------+-----+-------------------------------------------------+--------------------------------------------+\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_3301.jpg|105.75277709960938|60.255126953125   |378.000244140625  |610.764404296875  |0.7687336206436157|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.16523871, 0.094148636, 0.42538667, 0.8601707] |[105.75278, 60.255127, 272.24747, 550.5093] |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_3964.jpg|299.8299560546875 |220.64425659179688|431.216552734375  |362.1381530761719 |0.8760285377502441|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.4684843, 0.34475666, 0.20529155, 0.2210842]   |[299.82996, 220.64426, 131.3866, 141.4939]  |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_3964.jpg|187.54052734375   |236.48489379882812|248.49810791015625|362.1213073730469 |0.5272059440612793|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.29303208, 0.36950764, 0.09524622, 0.1963069]  |[187.54053, 236.4849, 60.95758, 125.63641]  |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_3976.jpg|23.57275390625    |0.0               |634.2537231445312 |570.5804443359375 |0.3318807780742645|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.03683243, 0.0, 0.954189, 0.89153194]          |[23.572754, 0.0, 610.68097, 570.58044]      |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_3984.jpg|238.28140258789062|206.19895935058594|630.8580322265625 |638.9921264648438 |0.724897027015686 |0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.3723147, 0.32218587, 0.613401, 0.6762393]     |[238.2814, 206.19896, 392.57663, 432.79315] |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4000.jpg|260.2042236328125 |201.7350311279297 |362.6234130859375 |311.78466796875   |0.8833895325660706|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.4065691, 0.315211, 0.16002998, 0.17195256]    |[260.20422, 201.73503, 102.41919, 110.04964]|\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4000.jpg|389.1451416015625 |423.3402099609375 |518.61669921875   |573.9592895507812 |0.7847627997398376|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.60803926, 0.6614691, 0.20229931, 0.23534231]  |[389.14514, 423.3402, 129.47156, 150.61908] |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4749.jpg|297.8525390625    |292.9383850097656 |353.67083740234375|364.1985168457031 |0.9008919596672058|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.4653946, 0.45771623, 0.087216094, 0.11134396] |[297.85254, 292.9384, 55.8183, 71.26013]    |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4749.jpg|575.4736328125    |97.70529174804688 |636.8985595703125 |452.1134948730469 |0.5165949463844299|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.89917755, 0.15266451, 0.09597645, 0.5537628]  |[575.47363, 97.70529, 61.424927, 354.4082]  |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4754.jpg|179.79302978515625|257.46514892578125|320.48193359375   |474.17645263671875|0.9124692678451538|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.28092661, 0.4022893, 0.21982642, 0.33861142]  |[179.79303, 257.46515, 140.6889, 216.7113]  |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4759.jpg|203.3727569580078 |231.37619018554688|541.08642578125   |611.33984375      |0.9006023406982422|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.31776994, 0.3615253, 0.5276776, 0.5936932]    |[203.37276, 231.37619, 337.71368, 379.96365]|\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4763.jpg|252.28909301757812|187.41714477539062|424.7012023925781 |502.8704528808594 |0.6175864934921265|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.3942017, 0.2928393, 0.26939392, 0.49289578]   |[252.2891, 187.41714, 172.41211, 315.4533]  |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4802.jpg|87.97184753417969 |235.7012939453125 |166.28196716308594|297.08416748046875|0.8676283955574036|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.13745601, 0.36828327, 0.12235956, 0.09591074] |[87.97185, 235.7013, 78.31012, 61.382874]   |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4802.jpg|320.9997863769531 |269.4732666015625 |384.7824401855469 |349.50390625      |0.7612653970718384|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.5015622, 0.42105198, 0.0996604, 0.12504788]   |[320.9998, 269.47327, 63.782654, 80.03064]  |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4876.jpg|193.64801025390625|68.91690063476562 |403.29107666015625|613.6182861328125 |0.79144287109375  |0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.30257502, 0.10768266, 0.32756728, 0.8510959]  |[193.64801, 68.9169, 209.64307, 544.7014]   |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4905.jpg|388.26055908203125|241.1764373779297 |531.1495971679688 |317.259033203125  |0.7396765351295471|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.60665715, 0.37683818, 0.22326413, 0.11887906] |[388.26056, 241.17644, 142.88904, 76.082596]|\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4905.jpg|70.40106201171875 |257.572509765625  |112.57084655761719|442.2135009765625 |0.7340518832206726|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.11000166, 0.40245706, 0.06589029, 0.28850156] |[70.40106, 257.5725, 42.169785, 184.64099]  |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4905.jpg|213.43576049804688|32.989837646484375|318.0753479003906 |615.7432861328125 |0.5433452129364014|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.33349338, 0.051546622, 0.16349936, 0.91055226]|[213.43576, 32.989838, 104.63959, 582.7534] |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4905.jpg|290.4571533203125 |260.3315124511719 |502.931396484375  |624.06298828125   |0.3868979811668396|0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.4538393, 0.406768, 0.33199102, 0.5683304]     |[290.45715, 260.3315, 212.47424, 363.73148] |\n",
            "|/content/drive/MyDrive/yolov5/customdata/images/test/giraffe_4908.jpg|370.7740478515625 |203.964111328125  |508.63433837890625|285.6918640136719 |0.832770824432373 |0       |Giraffa_tippelskirchi|Giraffa_tippelskirchi|2.0       |2.0  |[0.57933444, 0.31869394, 0.2154067, 0.12769961]  |[370.77405, 203.96411, 137.86029, 81.72775] |\n",
            "+---------------------------------------------------------------------+------------------+------------------+------------------+------------------+------------------+--------+---------------------+---------------------+----------+-----+-------------------------------------------------+--------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Verify that the conversion worked\n",
        "spark_yolo_val.show(20, False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "bins, counts = spark_yolo_val.select('confidence').rdd.flatMap(lambda x: x).histogram(10)\n",
        "plt.hist(bins[:-1], bins=bins, weights=counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T9_shFu7ntU",
        "outputId": "5d633645-845e-4767-9048-f5f874e2900d"
      },
      "id": "7T9_shFu7ntU",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([         30,          48,          45,          67,          92,          92,         132,         153,         228,         195]),\n",
              " array([    0.25264,      0.3224,     0.39216,     0.46192,     0.53169,     0.60145,     0.67121,     0.74097,     0.81073,     0.88049,     0.95026]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_yolo_val.filter(col('confidence') > .5).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLhdPlQn9qj2",
        "outputId": "be1fc04d-f3f0-4b2b-e48c-6a398d678084"
      },
      "id": "LLhdPlQn9qj2",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "926"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the distribution of confidence scores for incorrect predictions\n",
        "bins, counts = incorrect_bbs.select('confidence').rdd.flatMap(lambda x: x).histogram(10)\n",
        "plt.hist(bins[:-1], bins=bins, weights=counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXjJxMnvFvNY",
        "outputId": "2ef8ae03-8c0d-4adf-afef-db5550a66254"
      },
      "id": "GXjJxMnvFvNY",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([          3,           1,           1,           2,           1,           0,           0,           0,           0,           1]),\n",
              " array([    0.32244,     0.36281,     0.40317,     0.44354,     0.48391,     0.52427,     0.56464,       0.605,     0.64537,     0.68574,      0.7261]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the min and max values for correct versus incorrect predictions\n",
        "print(all_correct.groupBy().max('confidence').collect()[0].asDict()['max(confidence)'])\n",
        "print(all_correct.groupBy().min('confidence').collect()[0].asDict()['min(confidence)'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaEAvg7xBifb",
        "outputId": "9a80a13f-7fe9-481b-be16-8829b4b0693e"
      },
      "id": "yaEAvg7xBifb",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9502553939819336\n",
            "0.2526381313800812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the min and max values for correct versus incorrect predictions\n",
        "print(incorrect_bbs.groupBy().max('confidence').collect()[0].asDict()['max(confidence)'])\n",
        "print(incorrect_bbs.groupBy().min('confidence').collect()[0].asDict()['min(confidence)'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R32S_9hLB7pl",
        "outputId": "c7d4702a-7b3d-4afe-96dc-7fb1f3bce494"
      },
      "id": "R32S_9hLB7pl",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7261031866073608\n",
            "0.3224412500858307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the min and max values for correct versus incorrect predictions\n",
        "print(hyena_all_correct.groupBy().max('confidence').collect()[0].asDict()['max(confidence)'])\n",
        "print(hyena_all_correct.groupBy().min('confidence').collect()[0].asDict()['min(confidence)'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqbRWXMUCWfS",
        "outputId": "aa251401-6407-4e54-fc1c-9e806fbac69e"
      },
      "id": "nqbRWXMUCWfS",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9459032416343689\n",
            "0.2526381313800812\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "name": "yolo_test_preds&analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}